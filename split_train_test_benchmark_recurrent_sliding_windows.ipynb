{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from glob import glob\n",
    "\n",
    "from scipy.signal import butter, lfilter, convolve, boxcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creat_mne_raw_object(fname,read_events=True):\n",
    "    \"\"\"Create a mne raw instance from csv file\"\"\"\n",
    "    # Read EEG file\n",
    "    data = pd.read_csv(fname)\n",
    "    \n",
    "    # get chanel names\n",
    "    ch_names = list(data.columns[1:])\n",
    "    \n",
    "    # read EEG standard montage from mne\n",
    "    montage = read_montage('standard_1005',ch_names)\n",
    "\n",
    "    ch_type = ['eeg']*len(ch_names)\n",
    "    data = 1e-6*np.array(data[ch_names]).T\n",
    "    \n",
    "    if read_events:\n",
    "        # events file\n",
    "        ev_fname = fname.replace('_data','_events')\n",
    "        # read event file\n",
    "        events = pd.read_csv(ev_fname)\n",
    "        events_names = events.columns[1:]\n",
    "        events_data = np.array(events[events_names]).T\n",
    "        \n",
    "        # define channel type, the first is EEG, the last 6 are stimulations\n",
    "        ch_type.extend(['stim']*6)\n",
    "        ch_names.extend(events_names)\n",
    "        # concatenate event file and data\n",
    "        data = np.concatenate((data,events_data))\n",
    "        \n",
    "    # create and populate MNE info structure\n",
    "    info = create_info(ch_names,sfreq=500.0, ch_types=ch_type, montage=montage)\n",
    "    info['filename'] = fname\n",
    "    \n",
    "    # create raw object \n",
    "    raw = RawArray(data,info,verbose=False)\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = range(1,13)\n",
    "ids_tot = []\n",
    "pred_tot = []\n",
    "y_tot = []\n",
    "\n",
    "# design a butterworth bandpass filter \n",
    "freqs = [7, 30]\n",
    "b,a = butter(5,np.array(freqs)/250.0,btype='bandpass')\n",
    "\n",
    "# CSP parameters\n",
    "# Number of spatial filter to use\n",
    "nfilters = 4\n",
    "\n",
    "# convolution\n",
    "# window for smoothing features\n",
    "nwin = 250\n",
    "\n",
    "# training subsample\n",
    "subsample = 10\n",
    "\n",
    "# submission file\n",
    "submission_file = 'beat_the_benchmark.csv'\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "#for subject in subjects:\n",
    "for subject in [1]:\n",
    "    epochs_tot = []\n",
    "    y = []\n",
    "    \n",
    "    ################ READ DATA (FIRST SIX SERIES AS TRAINING DATA) ###########\n",
    "    fnames = []\n",
    "    for i in range(1, 7):\n",
    "        fnames.append('train/subj%d_series%d_data.csv' % (subject, i))\n",
    "    \n",
    "    # read and concatenate all the files\n",
    "    raw = concatenate_raws([creat_mne_raw_object(fname) for fname in fnames])\n",
    "       \n",
    "    # pick eeg signal\n",
    "    picks = pick_types(raw.info,eeg=True)\n",
    "    \n",
    "    # Filter data for alpha frequency and beta band\n",
    "    # Note that MNE implement a zero phase (filtfilt) filtering not compatible\n",
    "    # with the rule of future data.\n",
    "    # Here we use left filter compatible with this constraint\n",
    "    raw._data[picks] = lfilter(b,a,raw._data[picks])\n",
    "    \n",
    "    ################ CSP Filters training #####################################\n",
    "    # get event posision corresponding to Replace\n",
    "    events = find_events(raw,stim_channel='Replace', verbose=False)\n",
    "    # epochs signal for 1.5 second before the movement\n",
    "    epochs = Epochs(raw, events, {'during' : 1}, -2, -0.5, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "    \n",
    "    epochs_tot.append(epochs)\n",
    "    y.extend([1]*len(epochs))\n",
    "    \n",
    "    # epochs signal for 1.5 second after the movement, this correspond to the \n",
    "    # rest period.\n",
    "    epochs_rest = Epochs(raw, events, {'after' : 1}, 0.5, 2, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "    \n",
    "    # Workaround to be able to concatenate epochs with MNE\n",
    "    epochs_rest.times = epochs.times\n",
    "    \n",
    "    y.extend([-1]*len(epochs_rest))\n",
    "    epochs_tot.append(epochs_rest)\n",
    "        \n",
    "    # Concatenate all epochs\n",
    "    epochs = concatenate_epochs(epochs_tot)\n",
    "    \n",
    "    # get data \n",
    "    X = epochs.get_data()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # train CSP\n",
    "    csp = CSP(n_components=nfilters, reg='lws')\n",
    "    csp.fit(X,y)\n",
    "    \n",
    "    ################ Create Training Features #################################x`\n",
    "    # apply csp filters and rectify signal\n",
    "    feat = np.dot(csp.filters_[0:nfilters],raw._data[picks])**2\n",
    "    \n",
    "    # smoothing by convolution with a rectangle window    \n",
    "    feattr = np.zeros((feat.shape[0] + 6, feat.shape[1]))\n",
    "    for i in range(nfilters):\n",
    "        feattr[i] = np.log(convolve(feat[i],boxcar(nwin),'full'))[0:feat.shape[1]]\n",
    "    \n",
    "    # training labels\n",
    "    # they are stored in the 6 last channels of the MNE raw object\n",
    "    labels = raw._data[32:]\n",
    "    \n",
    "    # recurrent sliding window features (labels from previous time instance)\n",
    "    feattr[feat.shape[0]:, 1:] = labels[:, :-1]\n",
    "    \n",
    "    ################ Create test Features #####################################\n",
    "    # read test data (remaining series of train data)\n",
    "    fnames = []\n",
    "    for i in range(7, 9):\n",
    "        fnames.append('train/subj%d_series%d_data.csv' % (subject, i))\n",
    "        \n",
    "    raw = concatenate_raws([creat_mne_raw_object(fname) for fname in fnames])\n",
    "    raw._data[picks] = lfilter(b,a,raw._data[picks])\n",
    "    \n",
    "    # get actual y values\n",
    "    y = raw._data[32:]\n",
    "    y_tot.append(y.T)\n",
    "    \n",
    "    # read ids\n",
    "    ids = np.concatenate([np.array(pd.read_csv(fname)['id']) for fname in fnames])\n",
    "    ids_tot.append(ids)\n",
    "    \n",
    "    # apply preprocessing on test data\n",
    "    feat = np.dot(csp.filters_[0:nfilters],raw._data[picks])**2\n",
    "    featte = np.empty(feat.shape)\n",
    "    for i in range(nfilters):\n",
    "        featte[i] = np.log(convolve(feat[i],boxcar(nwin),'full'))[0:feat.shape[1]]\n",
    "    \n",
    "    ################ Train classifiers ########################################\n",
    "    lr = LogisticRegression()\n",
    "    pred = np.empty((len(ids),6))\n",
    "    for i in range(6):\n",
    "        X_train = feattr[:,::subsample].T\n",
    "        y_train = labels[i,::subsample]\n",
    "        X_test = featte.T\n",
    "    \n",
    "        print('Train subject %d, class %s' % (subject, cols[i]))\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        # Test best case, i.e. all last_pred correct\n",
    "        # Prepend zeros vector for first test instance\n",
    "        #X_test = np.hstack((featte.T, np.vstack(([0,0,0,0,0,0], y.T[:-1, :]))))\n",
    "        #pred[:, i] = lr.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Step through each prediction in test-set to get recurrent feature values\n",
    "        last_pred = np.zeros(6)\n",
    "        for k in range(len(X_test)):\n",
    "            if k > 0:\n",
    "                #last_pred = pred[k-1].round()              # Set to 1 any prediction over 0.5\n",
    "                #last_pred = pred[k-1]                      # Raw class preditions from previous\n",
    "                #last_pred = pred[k-1] == pred[k-1].max()   # Always choose largest class prediction\n",
    "                #last_pred = y.T[k-1]                       # Oracle\n",
    "                last_pred = pred[k-1] > 0.001               # Low threshold\n",
    "                \n",
    "            # Print out some test instances\n",
    "            #if k >=0 and k <10:\n",
    "            #    print 'Making prediction on test instance', np.hstack((X_test[k, :], last_pred))\n",
    "            pred[k, i] = lr.predict_proba(np.hstack((X_test[k, :], last_pred)))[:,1]\n",
    "    \n",
    "    pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AUC: 0.610579456977\n"
     ]
    }
   ],
   "source": [
    "y_score = np.concatenate(pred_tot)\n",
    "y_true = np.concatenate(y_tot)\n",
    "\n",
    "# Convert y_true to int matrix, auc calc will not work with floats\n",
    "y_true = y_true.astype(int)\n",
    "auc = roc_auc_score(y_true, y_score, average='macro')\n",
    "print 'Final AUC:', auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
