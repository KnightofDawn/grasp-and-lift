{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul  7 18:40:37 CEST 2015\n",
    "\n",
    "@author: Elena Cuoco\n",
    "simple starting script, without the use of MNE\n",
    "Thanks to @author: alexandrebarachant for his wornderful starting script\n",
    "Modified @author: Jonathan Rubin\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, convolve, boxcar\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n",
      "Train subject 2, class HandStart\n",
      "Train subject 2, class FirstDigitTouch\n",
      "Train subject 2, class BothStartLoadPhase\n",
      "Train subject 2, class LiftOff\n",
      "Train subject 2, class Replace\n",
      "Train subject 2, class BothReleased\n",
      "Train subject 3, class HandStart\n",
      "Train subject 3, class FirstDigitTouch\n",
      "Train subject 3, class BothStartLoadPhase\n",
      "Train subject 3, class LiftOff\n",
      "Train subject 3, class Replace\n",
      "Train subject 3, class BothReleased\n",
      "Train subject 4, class HandStart\n",
      "Train subject 4, class FirstDigitTouch\n",
      "Train subject 4, class BothStartLoadPhase\n",
      "Train subject 4, class LiftOff\n",
      "Train subject 4, class Replace\n",
      "Train subject 4, class BothReleased\n",
      "Train subject 5, class HandStart\n",
      "Train subject 5, class FirstDigitTouch\n",
      "Train subject 5, class BothStartLoadPhase\n",
      "Train subject 5, class LiftOff\n",
      "Train subject 5, class Replace\n",
      "Train subject 5, class BothReleased\n",
      "Train subject 6, class HandStart\n",
      "Train subject 6, class FirstDigitTouch\n",
      "Train subject 6, class BothStartLoadPhase\n",
      "Train subject 6, class LiftOff\n",
      "Train subject 6, class Replace\n",
      "Train subject 6, class BothReleased\n",
      "Train subject 7, class HandStart\n",
      "Train subject 7, class FirstDigitTouch\n",
      "Train subject 7, class BothStartLoadPhase\n",
      "Train subject 7, class LiftOff\n",
      "Train subject 7, class Replace\n",
      "Train subject 7, class BothReleased\n",
      "Train subject 8, class HandStart\n",
      "Train subject 8, class FirstDigitTouch\n",
      "Train subject 8, class BothStartLoadPhase\n",
      "Train subject 8, class LiftOff\n",
      "Train subject 8, class Replace\n",
      "Train subject 8, class BothReleased\n",
      "Train subject 9, class HandStart\n",
      "Train subject 9, class FirstDigitTouch\n",
      "Train subject 9, class BothStartLoadPhase\n",
      "Train subject 9, class LiftOff\n",
      "Train subject 9, class Replace\n",
      "Train subject 9, class BothReleased\n",
      "Train subject 10, class HandStart\n",
      "Train subject 10, class FirstDigitTouch\n",
      "Train subject 10, class BothStartLoadPhase\n",
      "Train subject 10, class LiftOff\n",
      "Train subject 10, class Replace\n",
      "Train subject 10, class BothReleased\n",
      "Train subject 11, class HandStart\n",
      "Train subject 11, class FirstDigitTouch\n",
      "Train subject 11, class BothStartLoadPhase\n",
      "Train subject 11, class LiftOff\n",
      "Train subject 11, class Replace\n",
      "Train subject 11, class BothReleased\n",
      "Train subject 12, class HandStart\n",
      "Train subject 12, class FirstDigitTouch\n",
      "Train subject 12, class BothStartLoadPhase\n",
      "Train subject 12, class LiftOff\n",
      "Train subject 12, class Replace\n",
      "Train subject 12, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "#############function to read data###########\n",
    "\n",
    "def prepare_data_train(fname):\n",
    "    \"\"\" read and prepare training data \"\"\"\n",
    "    # Read data\n",
    "    data = pd.read_csv(fname)\n",
    "    # events file\n",
    "    events_fname = fname.replace('_data','_events')\n",
    "    # read event file\n",
    "    labels= pd.read_csv(events_fname)\n",
    "    clean=data.drop(['id' ], axis=1)#remove id\n",
    "    labels=labels.drop(['id' ], axis=1)#remove id\n",
    "    return  clean,labels\n",
    "\n",
    "def butterworth_filter(X,t,k,l):\n",
    "    if t==0:\n",
    "        freq=[k, l]\n",
    "        b,a = butter(5,np.array(freq)/250.0,btype='bandpass')\n",
    "        X = lfilter(b,a,X)\n",
    "    elif t==1:\n",
    "        b,a = butter(5,k/250.0,btype='lowpass')\n",
    "        X = lfilter(b,a,X)\n",
    "    elif t==2:\n",
    "        b,a = butter(5,l/250.0,btype='highpass')\n",
    "        X = lfilter(b,a,X)      \n",
    "    return X\n",
    "\n",
    "def prepare_data_test(fname):\n",
    "    \"\"\" read and prepare test data \"\"\"\n",
    "    # Read data\n",
    "    data = pd.read_csv(fname)\n",
    "    return data\n",
    "\n",
    "scaler= StandardScaler()\n",
    "def data_preprocess_train(X):\n",
    "    X_prep_normal = scaler.fit_transform(X)\n",
    "    X_prep_low = np.zeros((np.shape(X_prep_normal)[0],10))\n",
    "    for i in range(10):\n",
    "        X_prep_low[:,i] = butterworth_filter(X[:,0],1,2-(i*0.2),3)\n",
    "        X_prep_low[:,i] = scaler.fit_transform(X_prep_low[:,i])\n",
    "    X_prep = np.concatenate((X_prep_low,X_prep_normal),axis=1)\n",
    "    #do here your preprocessing\n",
    "    return X_prep\n",
    "\n",
    "def data_preprocess_test(X):\n",
    "    X_prep_normal = scaler.transform(X)\n",
    "    X_prep_low = np.zeros((np.shape(X_prep_normal)[0],10))\n",
    "    for i in range(10):\n",
    "        X_prep_low[:,i] = butterworth_filter(X[:,0],1,2-(i*0.2),3)\n",
    "        X_prep_low[:,i] = scaler.transform(X_prep_low[:,i])\n",
    "    X_prep = np.concatenate((X_prep_low,X_prep_normal),axis=1)\n",
    "    return X_prep\n",
    "\n",
    "# training subsample.if you want to downsample the training data\n",
    "subsample = 1\n",
    "#######columns name for labels#############\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######number of subjects###############\n",
    "subjects = range(1,13)\n",
    "ids_tot = []\n",
    "pred_tot = []\n",
    "\n",
    "###loop on subjects and 8 series for train data + 2 series for test data\n",
    "for subject in subjects:\n",
    "    y_raw= []\n",
    "    raw = []\n",
    "    ################ READ DATA ################################################\n",
    "    fnames =  glob('train/subj%d_series*_data.csv' % (subject))\n",
    "    for fname in fnames:\n",
    "        data,labels=prepare_data_train(fname)\n",
    "        raw.append(data)\n",
    "        y_raw.append(labels)\n",
    "\n",
    "    X = pd.concat(raw)\n",
    "    y = pd.concat(y_raw)\n",
    "    #transform in numpy array\n",
    "    #transform train data in numpy array\n",
    "    X_train =np.asarray(X.astype(float))\n",
    "    y = np.asarray(y.astype(float))\n",
    "\n",
    "\n",
    "    ################ Read test data #####################################\n",
    "    #\n",
    "    fnames =  glob('test/subj%d_series*_data.csv' % (subject))\n",
    "    test = []\n",
    "    idx=[]\n",
    "    for fname in fnames:\n",
    "        data=prepare_data_test(fname)\n",
    "        test.append(data)\n",
    "        idx.append(np.array(data['id']))\n",
    "    X_test= pd.concat(test)\n",
    "    ids=np.concatenate(idx)\n",
    "    ids_tot.append(ids)\n",
    "    X_test=X_test.drop(['id' ], axis=1)#remove id\n",
    "    #transform test data in numpy array\n",
    "    X_test =np.asarray(X_test.astype(float))\n",
    "\n",
    "\n",
    "    ################ Train classifiers ########################################\n",
    "    lr = GradientBoostingClassifier()\n",
    "    pred = np.empty((X_test.shape[0],6))\n",
    "    X_train=data_preprocess_train(X_train)\n",
    "    X_test=data_preprocess_test(X_test)\n",
    "    for i in range(6):\n",
    "        y_train= y[:,i]\n",
    "        print('Train subject %d, class %s' % (subject, cols[i]))\n",
    "        lr.fit(X_train[::subsample,:],y_train[::subsample])\n",
    "        pred[:,i] = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "    pred_tot.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission file\n",
    "submission_file = 'raw_eeg_low_freq.csv'\n",
    "# create pandas object for sbmission\n",
    "submission = pd.DataFrame(index=np.concatenate(ids_tot),\n",
    "                          columns=cols,\n",
    "                          data=np.concatenate(pred_tot))\n",
    "\n",
    "# write file\n",
    "submission.to_csv(submission_file,index_label='id',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
